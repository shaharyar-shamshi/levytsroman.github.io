---
layout: Blogs
title: "Blog"
date: "7th May 2020"
description: "Web Scrapping using proxy server in python"
---

<div class="yetpublished">
    <h2 style="margin-left: 20px;" class="blog_title"> Web Scrapping using proxy server in python </h2>
    <div class="datepublished">
        <span>
            {{page.date}}
        </span>
    </div>
</div>
<div class="blog_content">
    <span> Many a time we come across the situation where we have to scrap the website but due to various factors like
        API time restrictions
        we are not able to scrap the website or we cannot fully scrap the website before being detected as a bot. so to
        solve this issue I am going to use
        selenium webdriver for Scrapping the website using a rotating proxy so for this we require a bunch of proxies if we
        have private IPs with us we can use that else
        in this blog I am going to scrap <a href="https://free-proxy-list.net/" target="_blank">
            https://free-proxy-list.net/ </a> to get a bunch of proxies
        so overall my blog is divided into two-part first is scraping to get IPs and second is using that IPs to scarp
        our intended website. <br>
        let's begin with scraping <a href="https://free-proxy-list.net/" target="_blank"> https://free-proxy-list.net/ </a>
            <br>
            for this, we will use Beautiful Soup which is a Python library for pulling data out of HTML and XML files. It
            works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse
            tree. <br>
            
             
            <p style="margin-top:20px"> code sample for scraping the <a href="https://free-proxy-list.net/" target="_blank"> https://free-proxy-list.net/ </a></p>
            <pre> 
                    <code> 
                            from bs4 import BeautifulSoup
                            import requests
                            
                            data = requests.get("https://free-proxy-list.net/")
                            
                            parseddata = BeautifulSoup(data.text, "html.parser")
                            ips = []
                            raw_ips = parseddata.findAll('table')[0].tbody.findAll('tr')
                            for ip in raw_ips:
                                data = ip.findAll('td')
                                ips.append(data[0].contents[0] + ":" + data[1].contents[0])
                            
                                
                    </code> 
                    </pre>

        <div>
            <span> This will give out the array of ip addresses in format ip:port and we will use this IPs to connect to external website
                kindly note Free proxies available on the internet are always abused and end up being in blacklists used by 
                anti-scraping tools and web servers. 
                If you are doing serious large-scale data extraction, you should pay for some good proxies. 
            </span>
            <span> 
                we can use any method to use this available IPs whether it be some random ip or we can use round-robin to pick up the
                IPs
            </span>
        </div>
    </span>
</div>